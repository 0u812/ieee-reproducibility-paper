\documentclass{article}

\usepackage{listings}
\lstset{
  showstringspaces=false
}
\usepackage{hyperref}

\begin{document}

\section*{S2. Comparing Implementations of Pseudo-Random Number Generators}

Here, we show that pseudo-random number generators (PRNGs) can be implemented in a standard way so that different implementations can generate identical output. In order to demonstrate this, we compare two implementations of the ubiquitous Mersenne-Twister algorithm \cite{matsumoto1998mersenne} based on the Boost random library (version 1.60, \href{www.boost.org/doc/libs/1\_60\_0/doc/html/boost\_random.html}{www.boost.org/doc/libs/1\_60\_0/doc/html/boost\_random.html}), authored by Jens Maurer, and the Python \verb|random| module, part of the Python standard library (version 2.7.10, \href{www.python.org}{www.python.org}).

We first hypothesized that implementations of PRNGs could in principle diverge due to (1) an incomplete specification of the algorithm in the original publication, (2) lack of documentation about the parameterization or variant used in a given implementation, or (3) idiosyncrasies of a particular implementation. We constructed an initial test for convergence by using identical variants of the Mersenne Twister with identical parameterization. We note that the parameterization and variant information was undocumented for the Python implementation. Hence, we had to compare the source code of the two implementations to ensure identical parameterization. We then seeded each implementation using the integer value 100. The code for this stage is shown in Figure \ref{fig:01} and Figure \ref{fig:02}.

We found that the results generated by the two implementations were not identical. Upon further investigation, we discovered that the implementations diverge with respect to the seed method. In both cases, the seed value (a single integer) is used to initialize the internal 624-dimentional state of the PRNG, but the exact mechanism used to perform this initialization differs. The Boost library allows the user to completely set the internal state of the PRNG. Hence, we used a 624-element vector to completely specify the internal state of the Boost PRNG, as shown in Supplementary Material S3. We populated this vector with elements derived from the initial state of the Python implementation. This values produced identical to the output of the Python implementation. The results are shown in \ref{fig:03}.

Our tests show that, while the underlying algorithm was implemented consistently in both Boost and Python, and the parameterization was identical, the implementation of initialization code was different. Thus, this corresponds to case (3) above: divergence due to idiosyncrasies of a particular implementation.

\begin{figure}
\begin{lstlisting}[language=C++]
#include "boost/random/mersenne_twister.hpp"
#include "boost/random/uniform_real_distribution.hpp"

#include <iostream>

int main() {
  boost::mt19937 m37;
  m37.seed(100);
  std::cout <<
    "First five pseudo-random numbers generated by "
    "Boost's Mersenne Twister implementation:\n"
    << m37() << ", " << m37() << ", " << m37() <<
    ", " << m37() << ", " << m37() << "\n";

  return 0;
}
\end{lstlisting}
\caption{Original C++ code}
\label{fig:01}
\end{figure}

\begin{figure}
\begin{lstlisting}[language=Python]
import random

random.seed(100)
print("First five pseudo-random numbers generated" +
      "by Python's random module:")
print("{}, {}, {}, {}, {}".format(
  random.getrandbits(32), random.getrandbits(32), random.getrandbits(32),
  random.getrandbits(32), random.getrandbits(32)))
\end{lstlisting}
\caption{Original Python code}
\label{fig:02}
\end{figure}

\begin{figure}
\begin{lstlisting}
First five pseudo-random numbers generated by Boost:
625644691, 1973661107, 1953896601, 4087596401, 3310491232

First five pseudo-random numbers generatedby Python's random module:
625644691, 1973661107, 1953896601, 4087596401, 3310491232
\end{lstlisting}
\caption{Comparing the output of C++ and Python implementations}
\label{fig:03}
\end{figure}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,model_reproducibility}

\end{document}